{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid19_Detection_Using_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZkmO7vLe34ciabxe1Hl4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/R06880/Covid19-Detection-Using-CNN/blob/main/Covid19_Detection_Using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxy9dprW4wa4"
      },
      "source": [
        "## ***Convolutional Neural Network to predict Covid19/Normal X-Rays***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5Q0PG4n4mul"
      },
      "source": [
        "# the images are in my google drive account, so we need to import drive\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7OL97aYYyXN",
        "outputId": "2e46d51f-b3b4-4cdb-ab6b-b4ffa70b665d"
      },
      "source": [
        "# making the connection to Google drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPCdwrKGcx8a",
        "outputId": "900598af-2a82-4b7e-92ea-5f5c214288ce"
      },
      "source": [
        "# import libraries\n",
        "# we will preprocess the images using the preprocessing modules from keras\n",
        "# we will import all layers and all models from Keras\n",
        "# we import PIL to load images\n",
        "\n",
        "from PIL import Image\n",
        "from tensorflow.python.keras.preprocessing import image\n",
        "from tensorflow.python.keras.layers import *\n",
        "from tensorflow.python.keras.models import * \n",
        "print('Imported Successfully!')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported Successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVASOAILc0-j",
        "outputId": "a0af0faa-4ad7-4f90-f516-a9eb0eda1f87"
      },
      "source": [
        "# making a data generator for train data and test data\n",
        "# we rescale the pixels between 0 and 1, because the pixels are between 0 and 255\n",
        "# shear range determines the angle to which we rotate the images\n",
        "# the zoom range determines the percentage of zoom\n",
        "\n",
        "# we don't need to create more test images, as we want to know the labels only for these pictures\n",
        "# we tranform the training images in order to have more training data and also to capture the features more accurately\n",
        "\n",
        "train_datagen = image.ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = image.ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "print('Created the Data Generator Objects.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created the Data Generator Objects.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz-CUaFqc5e2",
        "outputId": "e64752c4-69a9-4922-ad9c-5143f50fdfbc"
      },
      "source": [
        "# we create the training data by applying the generator to the training images\n",
        "# we create the validdation data by applying the generator to the validation images \n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/gdrive/My Drive/CovidDataset/Train',target_size=(224,224),batch_size=32, class_mode=\"binary\")\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory('/content/gdrive/My Drive/CovidDataset/Val',target_size=(224,224),batch_size=32, class_mode=\"binary\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 224 images belonging to 2 classes.\n",
            "Found 60 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PynopHSMdJwf",
        "outputId": "aa1892e3-57c4-45b5-e31f-563fe4b178e1"
      },
      "source": [
        "# now we create the model and add layers to it\n",
        "# the first layer is a convolutional layer, having a 3x3 kernel and the relu activation function\n",
        "# also, being the first layer in the network, we have to give it the input shape\n",
        "# in this case, we are using RGB images, so there are 3 channels, each one having 244x244 pixels\n",
        "# we then add another conv layer with a kernel size 3x3\n",
        "# these 2 layers are the equivalent of doing a single conv layer with the kernel size of 5x5\n",
        "# but instead of having 25 params to train, now we have 9+9 = 18\n",
        "# we reduce the size by applying a max pooling layer \n",
        "# then we use a dropout layer to avoid overfitting, by setting some of the neurons to 0\n",
        "# we repeat this process and then we feed this to an ANN, by using the flatten layer to tranform \n",
        "# the data to one dimension\n",
        "# the ANNS has a dense hidden layer with 64 neurons and the relu activation function\n",
        "# then we set half of the neurons to 0\n",
        "# we then add a dense layer with a single neuron because we a have a binary\n",
        "# classification problem\n",
        "# the last neuron has the activation function sigmoid, as we want the prob of an \n",
        "# image being covid or normal\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\",input_shape=(224,224,3)))\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, kernel_size=(3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# we compile the model with the adam optimizer\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics = [\"accuracy\"])\n",
        "\n",
        "# we can see the model\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 222, 222, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 220, 220, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 110, 110, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 108, 108, 128)     73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 54, 54, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 54, 54, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 373248)            0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                23887936  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 23,981,249\n",
            "Trainable params: 23,981,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d3dUpoTdVqG",
        "outputId": "ad78ddc4-d367-48b1-f85a-5b43f259ce8c"
      },
      "source": [
        "# now we fit the model to the training data, using the validation data to validate the model\n",
        "\n",
        "hist = model.fit(train_generator, epochs = 6, validation_data=val_generator, validation_steps=2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "7/7 [==============================] - 80s 11s/step - loss: 2.1756 - accuracy: 0.5624 - val_loss: 0.6476 - val_accuracy: 0.5000\n",
            "Epoch 2/6\n",
            "7/7 [==============================] - 78s 11s/step - loss: 0.6641 - accuracy: 0.6288 - val_loss: 0.5607 - val_accuracy: 0.9000\n",
            "Epoch 3/6\n",
            "7/7 [==============================] - 76s 11s/step - loss: 0.4389 - accuracy: 0.8209 - val_loss: 0.2225 - val_accuracy: 0.9500\n",
            "Epoch 4/6\n",
            "7/7 [==============================] - 76s 11s/step - loss: 0.2915 - accuracy: 0.8870 - val_loss: 0.2222 - val_accuracy: 0.9333\n",
            "Epoch 5/6\n",
            "7/7 [==============================] - 76s 11s/step - loss: 0.2589 - accuracy: 0.9340 - val_loss: 0.1388 - val_accuracy: 0.9667\n",
            "Epoch 6/6\n",
            "7/7 [==============================] - 76s 11s/step - loss: 0.1857 - accuracy: 0.9355 - val_loss: 0.0837 - val_accuracy: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s2HEWxndZLh"
      },
      "source": [
        "# We can see that after 6 epochs we got a validation accuracy of about 96.67%"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}